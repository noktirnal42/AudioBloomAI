# AudioBloomAI Documentation

Welcome to the AudioBloomAI project documentation! This wiki serves as the central knowledge base for developers and users of AudioBloomAI.

## Quick Links
- [Architecture Overview](Architecture-Overview)
- [Development Setup](Development-Setup)
- [Contributing Guidelines](Contributing-Guidelines)
- [API Documentation](API-Documentation)
- [Module Documentation](Module-Documentation)

## Project Overview
AudioBloomAI is a macOS application that combines audio processing with AI-driven visualization. The project is built using Swift and Metal, targeting macOS 15+ and leveraging the latest platform capabilities.

## Core Components
1. **AudioBloomCore**
   - Core functionality and settings management
   - Data publishing and event handling
   - Visual theme management

2. **AudioProcessor**
   - Metal-accelerated audio processing
   - Real-time feature extraction
   - Buffer management

3. **Visualizer**
   - Metal shader infrastructure
   - Real-time visualization
   - Effect management

## Development Status
The project is currently in Core Implementation (Phase 1), focusing on establishing the fundamental architecture and core functionality. See the [Project Board](https://github.com/users/noktirnal42/projects/1) for current progress.
